
models:
  LogisticRegression:
    class: "sklearn.linear_model.LogisticRegression"
    use_scaled: true
    parameters:
      random_state: 42
      max_iter: 1000
      class_weight: "balanced"
      solver: "liblinear"
      C: 1.0
      penalty: "l2"
  
  DecisionTree:
    class: "sklearn.tree.DecisionTreeClassifier"
    use_scaled: false
    parameters:
      random_state: 42
      max_depth: 5
      min_samples_split: 20
      min_samples_leaf: 10
      class_weight: "balanced"
      criterion: "gini"
  
  KNN:
    class: "sklearn.neighbors.KNeighborsClassifier"
    use_scaled: true
    parameters:
      n_neighbors: 11
      weights: "distance"
      metric: "euclidean"
    optimize_hyperparams: true
    param_grid:
      n_neighbors: [3, 5, 7, 9, 11, 13, 15]
      weights: ["uniform", "distance"]
  
  GaussianNB:
    class: "sklearn.naive_bayes.GaussianNB"
    use_scaled: false  # Naive Bayes doesn't need scaling
    parameters:
      var_smoothing: 1e-9
  
  RandomForest:
    class: "sklearn.ensemble.RandomForestClassifier"
    use_scaled: false  # Tree-based models don't need scaling
    parameters:
      n_estimators: 100
      max_depth: 10
      min_samples_split: 10
      min_samples_leaf: 5
      class_weight: "balanced"
      random_state: 42
      n_jobs: -1
    optimize_hyperparams: false
  
  XGBoost:
    class: "xgboost.XGBClassifier"
    use_scaled: false  # Tree-based models don't need scaling
    parameters:
      n_estimators: 100
      max_depth: 6
      learning_rate: 0.1
      objective: "binary:logistic"
      random_state: 42
      eval_metric: "logloss"
    optimize_hyperparams: false

evaluation:
  metrics:
    - "accuracy"
    - "auc_score"
    - "precision"
    - "recall"
    - "f1_score"
    - "mcc"
  cv_folds: 5
  scoring: "f1"
  
output:
  save_models: true
  save_metrics: true
  save_plots: true
  show_plots: false
  output_dir: "outputs"
  streamlit_output_dir: "outputs"
